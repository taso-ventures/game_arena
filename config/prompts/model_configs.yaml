# Model-specific configurations for prompt generation
# Each model has distinct token limits, output styles, and reasoning approaches
# that influence how game prompts are formatted and structured.

models:
  # OpenAI GPT models
  gpt-4:
    max_tokens: 4000
    style: "structured"
    reasoning: "chain_of_thought"
    format: "json_with_explanation"
    description: "OpenAI GPT-4 family with structured output"

  gpt-5:
    max_tokens: 4000
    style: "structured"
    reasoning: "chain_of_thought"
    format: "json_with_explanation"
    description: "OpenAI's GPT-5 with structured output and detailed reasoning"

  gpt:
    max_tokens: 3500
    style: "structured"
    reasoning: "chain_of_thought"
    format: "json_with_explanation"
    description: "OpenAI GPT models (fallback)"

  # Google Gemini models
  gemini:
    max_tokens: 3500
    style: "structured"
    reasoning: "step_by_step"
    format: "json_with_explanation"
    description: "Google Gemini models with structured reasoning"

  # Anthropic Claude models
  claude:
    max_tokens: 3500
    style: "conversational"
    reasoning: "step_by_step"
    format: "natural_with_tags"
    description: "Anthropic's Claude with natural conversation flow"

  # DeepSeek models
  deepseek:
    max_tokens: 3000
    style: "concise"
    reasoning: "direct"
    format: "structured_json"
    description: "DeepSeek with concise, direct reasoning approach"

  # xAI Grok models
  grok:
    max_tokens: 4000
    style: "structured"
    reasoning: "chain_of_thought"
    format: "json_with_explanation"
    description: "xAI Grok models with structured reasoning"

  # Ollama local models (Llama, Mistral, etc.)
  llama:
    max_tokens: 3500
    style: "structured"
    reasoning: "step_by_step"
    format: "json_with_explanation"
    description: "Llama models via Ollama for local inference"

  ollama:
    max_tokens: 3500
    style: "structured"
    reasoning: "step_by_step"
    format: "json_with_explanation"
    description: "Generic Ollama model configuration for local inference"

  # HuggingFace models
  huggingface:
    max_tokens: 3000
    style: "structured"
    reasoning: "step_by_step"
    format: "json_with_explanation"
    description: "HuggingFace models via Inference API"

  # Moonshot AI models
  kimi:
    max_tokens: 3500
    style: "structured"
    reasoning: "chain_of_thought"
    format: "json_with_explanation"
    description: "Moonshot AI Kimi K2 model (via Together.AI)"

  moonshot:
    max_tokens: 8000
    style: "structured"
    reasoning: "extended_thinking"
    format: "json_with_explanation"
    description: "Moonshot AI Kimi K2 Thinking model with extended reasoning capabilities"

# Style definitions for prompt formatting
styles:
  structured:
    use_headers: true
    bullet_points: true
    numbered_lists: true
    emphasis_markers: true

  conversational:
    use_headers: false
    bullet_points: false
    numbered_lists: false
    emphasis_markers: false

  concise:
    use_headers: true
    bullet_points: true
    numbered_lists: false
    emphasis_markers: false

# Reasoning approach definitions
reasoning_approaches:
  chain_of_thought:
    step_by_step: true
    show_reasoning: true
    explicit_conclusions: true

  step_by_step:
    step_by_step: true
    show_reasoning: true
    explicit_conclusions: false

  direct:
    step_by_step: false
    show_reasoning: false
    explicit_conclusions: true

  extended_thinking:
    step_by_step: true
    show_reasoning: true
    explicit_conclusions: true
    deep_analysis: true
    reasoning_budget: "high"

# Output format specifications
output_formats:
  json_with_explanation:
    use_json: true
    include_explanation: true

  natural_with_tags:
    use_json: false
    include_tags: true

  structured_json:
    use_json: true
    strict_structure: true
